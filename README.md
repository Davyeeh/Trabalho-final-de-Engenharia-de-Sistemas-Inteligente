# ğŸ¢ PrediÃ§Ã£o de PreÃ§os de Apartamentos em SÃ£o Paulo (API)

Este projeto Ã© o **Trabalho Final de Engenharia de Sistemas Inteligentes**. Ele consiste em uma soluÃ§Ã£o completa de **Machine Learning** para prever preÃ§os de venda de apartamentos na cidade de SÃ£o Paulo, utilizando dados como Ã¡rea, localizaÃ§Ã£o (bairro), nÃºmero de quartos e vagas de garagem.

A soluÃ§Ã£o expÃµe uma **API REST** construÃ­da com **FastAPI**, permitindo o treinamento do modelo e a realizaÃ§Ã£o de prediÃ§Ãµes de forma programÃ¡tica.

---

## ğŸš€ Como Executar o Projeto

Siga os passos abaixo para rodar a aplicaÃ§Ã£o localmente.

### PrÃ©-requisitos

- Python 3.12+  
- Poetry (Gerenciador de dependÃªncias)

### Passo a Passo

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/davyeeh/trabalho-final-de-engenharia-de-sistemas-inteligente.git
cd trabalho-final-de-engenharia-de-sistemas-inteligente
```

2. Instale as dependÃªncias:

```bash
poetry install
```

3. Ative o ambiente virtual:

```bash
poetry shell
```

4. Inicie a API:

```bash
python app.py
# Ou, se preferir usar o uvicorn diretamente:
# uvicorn app:app --reload
```

A API estarÃ¡ rodando em:  
ğŸ‘‰ http://127.0.0.1:8000

Acesse a documentaÃ§Ã£o (Swagger UI):  
ğŸ‘‰ http://127.0.0.1:8000/docs

---

## ğŸ› ï¸ Estrutura do Projeto

```plaintext
â”œâ”€â”€ app.py                   # Ponto de entrada da API (FastAPI) e rotas
â”œâ”€â”€ pyproject.toml           # ConfiguraÃ§Ã£o do projeto e dependÃªncias (Poetry)
â”œâ”€â”€ README.md                # DocumentaÃ§Ã£o do projeto
â”‚
â”œâ”€â”€ artifacts/               # Pasta onde o modelo treinado (.pkl) Ã© salvo
â”‚   â””â”€â”€ modelo_campeao.pkl
â”‚
â”œâ”€â”€ dados/                   # Armazenamento do histÃ³rico de dados processados
â”‚   â””â”€â”€ historico_apartamentos.csv
â”‚
â”œâ”€â”€ dataset/                 # Dados brutos originais (fonte de dados)
â”‚   â”œâ”€â”€ dataset_original.csv
â”‚   â””â”€â”€ SaoPaulo_OnlyAppartments_2024-11-25.csv
â”‚
â”œâ”€â”€ notebooks/               # Jupyter Notebooks para anÃ¡lises e testes
â”‚   â”œâ”€â”€ projeto_final_ESI.ipynb
â”‚   â””â”€â”€ Treinamento_ESI.ipynb
â”‚
â””â”€â”€ src/                     # CÃ³digo fonte do pipeline de ML
    â”œâ”€â”€ pipeline_dados.py    # LÃ³gica de limpeza e engenharia de features
    â””â”€â”€ pipeline_modelos.py  # LÃ³gica de treinamento e validaÃ§Ã£o
```

---

## ğŸ§  Funcionamento do Pipeline

### 1. Tratamento de Dados (`src/pipeline_dados.py`)

O sistema recebe os dados brutos e aplica as seguintes transformaÃ§Ãµes:

- **Limpeza:** RemoÃ§Ã£o de nulos em coordenadas (Latitude/Longitude).
- **Outliers:** Filtragem de preÃ§os discrepantes usando IQR (Interquartile Range).
- **Engenharia de Features:**
  - ExtraÃ§Ã£o do ano da data de criaÃ§Ã£o do anÃºncio.
  - PadronizaÃ§Ã£o de nomes de bairros.
- **PadronizaÃ§Ã£o:** Renomeia colunas para o padrÃ£o esperado pelo modelo (CamelCase).

### 2. Modelagem (`src/pipeline_modelos.py`)

Pipeline do Scikit-Learn contendo:

- **PrÃ©-processador (ColumnTransformer):**
  - VariÃ¡veis NumÃ©ricas: imputaÃ§Ã£o pela mediana + `StandardScaler`.
  - VariÃ¡veis CategÃ³ricas (bairro): `OneHotEncoder`.
- **Modelo Preditivo:**
  - XGBoost Regressor ou Random Forest Regressor.
  - OtimizaÃ§Ã£o baseada em RMSE e RÂ².

---

## ğŸ“¡ Endpoints da API

### `POST /train`

Retreina o modelo a partir de um arquivo CSV ou Excel.

- **Input:** `.csv` ou `.xlsx`
- **AÃ§Ã£o:**  
  - Limpa os dados  
  - Atualiza o histÃ³rico (`dados/`)  
  - Treina o modelo  
  - Salva em `artifacts/`

### `POST /predict`

Retorna o preÃ§o estimado de um imÃ³vel.

**Body (JSON):**

```json
{
  "area": 57,
  "bedrooms": 2,
  "bathrooms": 1,
  "parking_spaces": 1,
  "neighborhood": "Pinheiros",
  "latitude": -23.56,
  "longitude": -46.69,
  "created_date": 2024
}
```

**Response:**

```json
{
  "preco_estimado": 650000.0,
  "neighborhood": "Pinheiros"
}
```

---

## ğŸ§ª Testes e Notebooks

Para testar o fluxo completo sem Postman ou Insomnia, utilize:

- `notebooks/Treinamento_ESI.ipynb`
- `projeto_final_ESI.ipynb`

Esses notebooks permitem:

- Carregar o dataset original  
- Enviar dados para a rota de treino  
- Executar prediÃ§Ãµes de teste  
